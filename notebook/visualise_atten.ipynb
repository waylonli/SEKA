{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from transformers import AutoTokenizer",
   "id": "b7107522224bc31b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch, gc, seaborn as sns, matplotlib.pyplot as plt\n",
    "import sys  \n",
    "sys.path.insert(1, '../')\n",
    "from src.model import SEKALLM                     # ← your new wrapper\n",
    "from src.utils   import encode_with_markers            # unchanged\n",
    "\n",
    "# ---------- 1. prompt -------------------------------------------------\n",
    "tok      = AutoTokenizer.from_pretrained('../pretrained/Qwen3-4B-Base')\n",
    "ks = SEKALLM(\"../pretrained/Qwen3-4B-Base\", output_attentions=True)"
   ],
   "id": "2639f3d28caace8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = (\n",
    "    \"Previously Joachim Barrande was employed in Prague. Currently Joachim Barrande **was employed in Oslo**. Joachim Barrande worked in\"\n",
    ")\n",
    "ids, msk, _ = encode_with_markers(prompt, tok)        # ids:(1,seq)  msk:(seq,)\n",
    "ids      = ids.to(\"mps\");  device = ids.device\n",
    "\n",
    "ks.remove_projection()\n",
    "\n",
    "with torch.no_grad():\n",
    "    base_out  = ks.model(ids, output_attentions=True, use_cache=False)\n",
    "base_attn = [l.detach().cpu() for l in base_out.attentions]\n",
    "\n",
    "# ---------- 3. inject φ‑space K‑projection ---------------------------\n",
    "ks.attach_projection(\n",
    "    pos_pt=\"../projections/synthetic_new/Qwen3-4B-Base_pos_proj.pt\",\n",
    "    neg_pt=\"../projections/synthetic_new/Qwen3-4B-Base_neg_proj.pt\",\n",
    "    layers=\"all\",\n",
    "    steer_mask_tensor=msk,\n",
    "    amplify_pos=1.5,                # tune as needed\n",
    "    amplify_neg=0.3,                # tune as needed\n",
    "    # feature_function=\"squared-exponential\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    steer_out = ks.model(ids, output_attentions=True, use_cache=False)\n",
    "steer_attn = [l.detach().cpu() for l in steer_out.attentions]\n",
    "\n",
    "gc.collect()\n",
    "print(\"✓ collected baseline and steered attentions\")"
   ],
   "id": "7efa35cf7bdd139"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---------- 4. visual helper -----------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def show_pair(b_attn, s_attn, layer: int, head: int | None = None, vmax: float | None = None):\n",
    "    B = b_attn[layer][0]\n",
    "    S = s_attn[layer][0]\n",
    "    if head is None:\n",
    "        B = B.mean(0)\n",
    "        S = S.mean(0)\n",
    "        ttl = f\"L{layer+1} | mean of all heads\"\n",
    "    else:\n",
    "        B = B[head]\n",
    "        S = S[head]\n",
    "        ttl = f\"L{layer+1}, H{head+1}\"\n",
    "    vmax = float(max(B.max(), S.max())) if vmax is None else vmax\n",
    "    tokens = tok.convert_ids_to_tokens(ids[0].tolist())\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom\", [\"#fffbe0\", \"#006400\"])\n",
    "    mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    fig_width = max(12, 0.32 * len(tokens))\n",
    "    fig = plt.figure(figsize=(fig_width, 5))\n",
    "    gs = GridSpec(1, 2, width_ratios=[1,1], wspace=0.04, left=0.06, right=0.88, bottom=0.15, top=0.87)\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    for ax, mat, title in zip([ax1, ax2], [B, S], [\"Original\", \"SEKA\"]):\n",
    "        sns.heatmap(\n",
    "            mat.numpy(), ax=ax, cmap=cmap,\n",
    "            vmin=0, vmax=vmax, cbar=(ax is ax2), square=True\n",
    "        )\n",
    "        ax.set_title(f\"{title} - {ttl}\", fontsize=16, fontname=\"Times New Roman\")\n",
    "        ax.set_xticks(range(len(tokens)))\n",
    "        ax.set_xticklabels(tokens, rotation=90, fontsize=9, fontname=\"Times New Roman\")\n",
    "        ax.set_yticks(range(len(tokens)))\n",
    "        ax.set_yticklabels(tokens, rotation=0, fontsize=9, fontname=\"Times New Roman\")\n",
    "\n",
    "    fig.savefig(f\"attention_visualisation/Qwen3-4B-Base-L{layer+1}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ---------- 5. example ------------------------------------------------\n",
    "\n",
    "for l in range(15,36):\n",
    "    show_pair(base_attn, steer_attn, layer=l, head=None)   # avg heads\n",
    "# show_pair(base_attn, steer_attn, layer=25, head=8)    # one head"
   ],
   "id": "b1df8caea81759dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f7387133e6a7311d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
